############################
##### INPUT PARAMETERS #####
############################
# The rundir parameter is the name of a subdirectory under data/ that must contain
# - asv_seqs.fasta (ASV sequences in FASTA format) 
# - asv_counts.tsv (counts of ASVs (rows) in samples (columns)) 
# - and asv_taxa.tsv (taxonomic assignments of each ASV)
rundir: "test"
# The run_name parameter is the name of the workflow run and is used to separate
# runs with specific parameters of the clustering tools. 
# With different run_name parameters on the same rundir you can cluster the ASVs
# while automatically using the same alignment output (from vsearch).
run_name: "run1"
# With the split_rank parameter you can split the ASVs by a certain taxonomic rank
# prior to alignment and clustering, which parallellizes the workflow and can help
# speed things up on large datasets. 
# Note that the split_rank must exactly match one of the columns in the asv_taxa.tsv file
split_rank: "Family"
# The ranks parameter specifies what taxonomic ranks are included in the asv_taxa.tsv taxonomy file
ranks: 
  - "Kingdom"
  - "Phylum"
  - "Class"
  - "Order"
  - "Family"
  - "Genus"
  - "Species"
  - "BOLD_bin"

###############################
##### TAXONOMY PARAMETERS #####
###############################
# The evaluation rank parameter specifies what taxonomic rank to use for evaluating
# the clustering results. This rank should correspond to the taxonomic rank that
# you expect the clustering to represent, e.g. if you expect the clustering to
# represent species, set this parameter to "Species".
evaluation_rank: "Species"
# Ranks to use for calculating consensus taxonomy for clusters
consensus_ranks:
  - "Family"
  - "Genus"
  - "Species"
# % threshold to use for calculating consensus taxonomy for clusters
# As an example, if a cluster has 10 sequences, and at least 8 of them are classified
# as "Species X" at the Species level, the consensus taxonomy for the cluster
# will be "Species X" if the threshold is set to 80, otherwise taxonomy will
# be attempted to be resolved at Genus level etc.
consensus_threshold: 80

########################################
##### CHIMERA FILTERING PARAMETERS #####
########################################
chimera:
  # Set a run name for the chimera detection and removal step
  run_name: "chimera1"
  
  # Should chimera detection and removal be performed on the input data?
  remove_chimeras: True
  
  # Select method for chimera filtering:
  #'batchwise' = run chimera detection on dataset as a whole.
  #'samplewise' = split input fasta into one file per sample and run chimera
  #               detection on each sample individually.
  method: "samplewise"
  
  # Select algorithm to use, you can choose from 'uchime_denovo', 'uchime2_denovo'
  # and 'uchime3_denovo'.
  algorithm: "uchime_denovo"
  
  # In batchwise method, require that a sequence marked as chimeric is present
  # with its parents in at least <min_samples_shared> samples
  min_samples_shared: 1
  
  # In batchwise method, require that a sequence marked as chimeric is present
  # with its parents in at least <min_frac_samples_shared> fraction of samples
  min_frac_samples_shared: 0
  
  # In samplewise method, require that a sequence is marked as chimeric in at least
  # <min_chimeric_samples> in order for it to be removed from analysis. If this
  # value is set to 0, ASVs have to be marked as chimeric in all samples
  min_chimeric_samples: 0
  
  # In samplewise method, require that a sequence is marked as chimeric in at least
  # <min_frac_chimeric_samples> fraction of samples in which the ASV is present in 
  # order for it to be removed from analysis. If this value is set to 0, ASVs have 
  # to be marked as chimeric in all samples
  min_frac_chimeric_samples: 0
  
  # Thec parameters below are specific to how the chimeric score of sequences is
  # calculated. Please see the Uchime
  # [docs](https://www.drive5.com/usearch/manual6/UCHIME_score.html) for
  # details. Note that these are not used for uchime2_denovo or uchime3_denovo.
  # Instead these algorithms require 'perfect chimeras' (see the Uchime manual
  # for more info)
  dn: 1.4
  mindiffs: 3
  mindiv: 0.8
  minh: 0.28

###################################
##### CLUSTERING TOOLS TO RUN #####
###################################
# Specify what clustering software to use. Choose from 'swarm', 'opticlust',
# 'dbotu3' and 'lulu'.
software:
  - "swarm"
  #- "opticlust"
  #- "lulu"
  #- "dbotu3"

####################################
##### TOOL-SPECIFIC PARAMETERS #####
####################################
vsearch:
  # threads to use for vsearch (overridden in dardel profile)
  threads: 10
  
  # minimum pairwise identity to report
  id: 0.84
  
  # pairwise identity definition (see vsearch manual for details and choices)
  iddef: "1"

  # threshold for query coverage
  # reject hits if fraction of query aligned is less than this value
  query_cov: 0.9

opticlust:
  # For opticlust, choose whether pairwise alignments should be generated with
  # 'vsearch' or 'mothur'
  aligner: "vsearch"
  
  # The delta parameter sets the stable value for the metric in opticlust
  delta: 0.0001
  
  # sat what similarity threshold clusters are generated. 
  cutoff: 0.05

  # The `initialize` parameter sets the initial randomization for opticlust.
  # The default is `singleton` where each sequence is randomly assigned to its
  # own OTU. The other accepted setting `oneotu` means that all sequences are
  # assigned to one otu. 
  initialize: "singleton"

  # the floating point precision for opticlust.
  precision: 1000

  # the number of threads to use for opticlust
  # (overridden in dardel profile)
  threads: 10

swarm:
  # number of differences allowed to cluster sequences
  differences: 13

  # setting 'no-otu-breaking' to True deactivates the built-in cluster
  # refinement when d=1
  no-otu-breaking: False

  # if 'fastidious' is set to True swarm performs a second clustering pass to
  # reduce the number of small clusters when d=1
  fastidious: False

  # when 'fastidious' is set to True 'boundary' defines the minimum abundance of
  # what should be considered a large cluster.
  boundary: 0

  # the number of threads to use for swarm (overridden in dardel profile)
  threads: 10

  # the settings below modify the pairwise global alignment scoring parameters
  # when d>1
  match-reward: 5
  mismatch-penalty: 4
  gap-opening-penalty: 12
  gap-extension-penalty: 4

dbotu3:
  # dist sets the maximum allowed genetic dissimilarity between sequences
  dist: 0.1

  # abund sets the minimum fold difference for comparing two OTUs
  abund: 10.0

  # pval sets the minimum p-value for merging ASVs
  pval: 0.0005

###########################
##### NUMTs FILTERING #####
###########################
numts:
  # in NUMTs filtering, n_closest defines how many potential closely related
  # parent clusters to use in the comparison when identifying NUMTs. Setting
  # this to a higher value increases the chances to identify NUMTs but results
  # in longer runtimes.
  n_closest: 5

  # non_numt_ASVs is a list of ASV ids that are known to be non-numts. These are
  # used to evaluate the NUMTs filtering.
  non_numt_ASVs: ""

  # spikein_file is a tab-separated file with taxonomic information for
  # biological spike ins. This file should have either species labels or
  # BOLD_bin ids The file should have either 'Species' or 'BOLD_bin' columns.
  # Multiple BOLD_bins can be given on the same row and should then be quoted
  # and separated by a ';'. Below is an example. 
  # Species           BOLD_bin
  # Orius majusculus  BOLD:ABA5781 
  # Aphidius colemani "BOLD:AAC7809; BOLD:AAI4338"
  spikein_file: ""
  
  # spikein_method determines how clusters corresponding to biological spike ins
  # are identified. This setting can be either 'BOLD_bin' or 'Species' which
  # means that clusters will be identified either using the BOLD_bin or Species
  # values in the spike in file, respectively.
  spikein_method: "BOLD_bin"

  # specify which orders (if any) are known to contain a large number of clusters
  # if any order has > 10 k clusters then add them to this list
  # this will increase the resources (threads) requested when running numt filtering
  large_orders: ["Diptera"]
  
  # filter_unclassified_rank sets a taxonomic rank to used for filtering ASV clusters without a taxonomic assignments.
  # For example, when this parameter is set to "Order", all ASV clusters that are unclassified at the Order level will be considered NUMTs.
  # These clusters are not evaluated in the main NUMTs filtering algorithm but are likely to be NUMTs due to the lack of taxonomic information.
  filter_unclassified_rank: "Order"

###########################
##### POSTPROCESSING ######
###########################

# Parameters below specify whether to remove ASVs that are present in a certain
# fraction of 'blank' samples. For this to work you must supply a path to a
# tab-separated metadata file with at least one column specifying the sample ids
# and one column specifying the sample type. The blanks can be labelled in any way
# as long as they are distinct from the other sample types. The

# set postprocess to True to remove ASVs that are present in a certain fraction of
# 'blank' samples
postprocess: False

# specify path to a tab-separated metadata file (see above)
metadata_file: ""

# name of column in metadata file that contains sample ids
sample_id_col: ""

# sample_type_col is the name of the column in the metadata file that specifies the
# sample type
sample_type_col: ""

# blank_val is a list of values in the sample_type_col that correspond to blank samples
blank_val: []

# max_blank_occurrence is the maximum percentage of blanks that an ASV can be present
# in before it is removed from the dataset. Note that if a cluster contains at least one ASV
# that is present in more than max_blank_occurrence, the entire cluster is removed.
max_blank_occurrence: 5

# split_col is the column in the metadata file that specifies what samples
# belong to the same dataset. This is used to split the samples by dataset for counting
# occurence in blanks.
split_col: ""