from snakemake.utils import validate
from scripts.common import read_taxa

validate(config, schema="schemas/config.schema.yaml", set_default=True)
taxa = read_taxa(config)
wildcard_constraints:
    prog = "(swarm|opticlust|dbotu3|lulu)",
    taxa = taxa,
    rundir = config["rundir"]

container: "docker://continuumio/miniconda3:4.11.0"
include: "rules/common.smk"
include: "rules/swarm.smk"
include: "rules/dbotu3.smk"
include: "rules/opticlust.smk"
include: "rules/lulu.smk"

localrules:
    precision_recall,
    collate

def cluster_files(wildcards):
    input = []
    rundir = config["rundir"]
    for prog in config["software"]:
        run_name = config[prog]["run_name"]
        input.append(f"results/{prog}/{rundir}/{run_name}/precision_recall.txt")
    return input

def log_files(wildcards):
    input = []
    rundir = config["rundir"]
    for prog in config["software"]:
        run_name = config[prog]["run_name"]
        input.append(f"logs/{tool}/{rundir}/{run_name}/precision_recall.log")
    return input


rule collate:
    input:
        txt = cluster_files,
        log = log_files
    output:
        expand("results/stats/{rundir}/{run_name}.tsv", rundir = config["rundir"], run_name = config["run_name"])
    run:
        stats = {}
        for f in input.txt:
            tool = f.split("/")[1]
            with open(f, 'r') as fhin:
                items = {}
                for i, line in enumerate(fhin):
                    items[i] = line.rstrip().split(" ")[-1]
                stats[tool] = {'clusters': items[0], 'species': items[1],
                               'precision': items[6], 'recall': items[7]}
        for f in input.log:
            tool = f.split("/")[1]
            with open(f, 'r') as fhin:
                for line in fhin:
                    line = line.rstrip()
                    if line.endswith("ASVs remaining after merging"):
                        stats[tool]['ASVs'] = line.split(" ")[0].lstrip("#")
        df = pd.DataFrame(stats).T
        df.to_csv(output[0], sep="\t")



rule precision_recall:
    input:
        clust_files = expand("results/{{tool}}/{{rundir}}/{tax}/{{run_name}}/asv_clusters.tsv", tax = taxa),
        tax = expand("data/{rundir}/asv_taxa.tsv", rundir=config["rundir"])
    output:
        "results/{tool}/{rundir}/{run_name}/precision_recall.txt"
    log:
        "logs/{tool}/{rundir}/{run_name}/precision_recall.log"
    params:
        src = "workflow/scripts/evaluate_clusters.py",
        eval_rank = config["evaluation_rank"]
    shell:
        """
        python {params.src} {input.tax} {input.clust_files} --rank {params.eval_rank} > {output} 2>{log}
        """
